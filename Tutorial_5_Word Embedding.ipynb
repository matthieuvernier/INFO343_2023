{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00db8774",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "\n",
    "## Motivación\n",
    "\n",
    "¿Cómo representar las dimensiones semánticas de cada palabra?\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "1. Quiero una naranja.\n",
    "2. Quiero una manzana.\n",
    "\n",
    "Los métodos que toman en cuenta solo la forma de las palabras no tienen la capacidad de calcular que las frases 1 y 2 tienen un sentido \"similar\". \n",
    "\n",
    "Necesitamos una manera de representar que las palabras 'naranja' y 'manzana' comparten caracterícas semánticas comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef479d27",
   "metadata": {},
   "source": [
    "## Definición de \"Word Embedding\"\n",
    "\n",
    "El concepto de **word embedding** se refiere a un conjunto de técnicas utilizadas para aprender representaciones matemáticas de la \"semántica\" de cada palabra. El objeto matemático que permite representar la semántica de una palabra es el **vector**.\n",
    "\n",
    "Una de las técnicas más populares es __Word2Vec__ propuesto por un equipo de investigación de Google en 2013 (Efficient Estimation of Word Representations in Vector Space [Mikolov et al., 2013]). Alternativas populares se basan sobre __GloVe__ (propuesta por la Universidad de Stanford en 2014) y __FastText__ (propuesta por Facebook en 2016), que extende Word2Vec para considerar de mejor manera las palabras con errores ortográficas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21d25d",
   "metadata": {},
   "source": [
    "<img src=\"img/word2vec4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb36a81",
   "metadata": {},
   "source": [
    "Habitualmente, en tratamiento automático del lenguaje, se representan las palabras con vectores de 25, 50, 100 o 300 dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf84801",
   "metadata": {},
   "source": [
    "## Un ejemplo práctico para acercarse al concepto de Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec91c33",
   "metadata": {},
   "source": [
    "La clase <code>word2vec</code> de Gensim permite manejar word embeddings de palabras (ver documentación: https://radimrehurek.com/gensim/models/word2vec.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1b3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9a2f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word2vec.Text8Corpus('data/text8.txt')\n",
    "model = word2vec.Word2Vec(sentences,vector_size=200,hs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d0d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/text8_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "427217eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=word2vec.Word2Vec.load(\"data/text8_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1411d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=71290, vector_size=200, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "261a0106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4750526 ,  0.28976187,  0.38863212, -0.9668308 ,  0.80221444,\n",
       "        1.5536107 , -0.7473335 , -1.2108333 ,  0.9019541 , -0.08830222,\n",
       "       -1.1577853 , -0.43256226,  0.67274344,  0.4902007 ,  0.5526762 ,\n",
       "        1.0338655 ,  1.294052  , -1.8699862 , -0.12018216, -0.17123851,\n",
       "       -0.12552847,  0.96788377, -1.3385379 ,  0.7592566 , -0.72655714,\n",
       "       -0.41344744,  0.32699534,  0.54991597, -1.0608418 ,  0.11056432,\n",
       "        0.419322  ,  0.12575264,  1.7193593 , -0.55634993, -0.7909115 ,\n",
       "        0.6164369 ,  0.8432884 , -1.0142394 , -1.4164286 ,  1.2311203 ,\n",
       "       -0.74148065,  0.8788119 , -0.5071327 , -0.46919817,  0.8426847 ,\n",
       "        1.4220482 , -0.8212121 , -0.21774657,  0.9496805 , -0.47412476,\n",
       "       -0.03405823, -1.2005451 , -0.8131298 , -0.30827165, -0.67405665,\n",
       "       -0.10851738, -0.333103  , -0.3722968 ,  0.09006216, -1.452254  ,\n",
       "       -0.86730033,  0.4266357 , -0.68121684,  0.96824515,  1.2678099 ,\n",
       "       -0.8802508 , -1.1197585 ,  1.1102018 , -0.45635596, -2.1833005 ,\n",
       "       -2.1253898 , -0.24459025, -1.0258541 , -0.41568705,  1.6630507 ,\n",
       "       -0.56291807,  1.5355235 , -0.4019335 , -2.9606254 ,  0.64411503,\n",
       "       -1.4755877 ,  0.51308763,  0.4144386 , -0.25034067,  0.17469503,\n",
       "       -1.8268474 ,  1.2736117 , -0.9254278 , -0.07217469,  0.44128972,\n",
       "        0.4699377 ,  0.47630987,  0.5795323 , -0.6237495 ,  0.3233484 ,\n",
       "        0.04887681,  0.01793285, -1.9222778 , -1.3958935 ,  0.45312488,\n",
       "        0.35721737,  0.42396528,  0.60297596, -0.89109594,  0.67753965,\n",
       "       -1.4445375 , -1.1968555 ,  0.06001687,  2.1941187 , -0.10713995,\n",
       "        0.5218429 , -0.1771779 ,  0.574934  ,  1.2651477 , -0.5438316 ,\n",
       "       -1.6363783 , -1.4244264 ,  0.15322345,  0.02930227,  1.5798701 ,\n",
       "        0.4672816 ,  0.2606924 ,  0.5132939 ,  0.36015505,  1.9203681 ,\n",
       "       -0.3703113 , -1.4892263 ,  1.5363647 ,  0.7149496 ,  0.3243232 ,\n",
       "       -0.15699206, -0.7719471 ,  0.38898167, -0.6686342 ,  0.17133893,\n",
       "       -0.28956017,  1.1418476 ,  0.85282207,  0.1075443 ,  0.07537375,\n",
       "        0.44748127,  0.28242835, -0.6021907 ,  0.94231087, -0.96387357,\n",
       "        1.1424603 ,  0.8079662 ,  0.46727338, -0.44525135, -1.4683102 ,\n",
       "       -0.6049328 ,  0.18679419, -0.03565931, -0.46241847,  0.5150022 ,\n",
       "        0.72727835,  0.2675403 , -1.7616192 ,  0.9502103 , -0.44657475,\n",
       "        0.7848819 , -0.17792395,  0.9322647 ,  0.9460063 , -0.42796788,\n",
       "        0.18005247, -0.45644873, -0.0917294 ,  0.15993628, -0.9242856 ,\n",
       "       -1.3522499 ,  0.45551673,  1.8910183 ,  0.03669566,  0.34123114,\n",
       "        0.05049157, -1.5720336 ,  0.5918632 , -1.0421343 , -0.9662271 ,\n",
       "       -0.25174135, -1.2665769 , -0.10899244, -0.38642332, -0.17609768,\n",
       "       -0.94885105, -1.0821298 ,  0.37408337, -0.30980286,  1.6691247 ,\n",
       "        0.3909085 , -0.48838136,  0.03957437,  0.61204755, -0.30731878,\n",
       "        1.1478759 , -0.06136148,  0.0082118 , -0.9942348 , -0.41486442],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff893a4",
   "metadata": {},
   "source": [
    "Los parámetros de cada vector fueron aprendidos a través de un proceso de aprendizaje supervisado de una red neuronal, utilizando una dataset de entrenamiento. Las técnicas más comunes para aprender vectores de palabras se llaman CBOW (continuous bag of words) y Skip gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7152928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('childhood', 0.5218274593353271),\n",
       " ('lives', 0.4888582229614258),\n",
       " ('career', 0.48029983043670654),\n",
       " ('mankind', 0.4540000259876251),\n",
       " ('humanity', 0.45173171162605286)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['life'],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b3b776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('confrontation', 0.5610774755477905),\n",
       " ('weapons', 0.5424944162368774),\n",
       " ('fighting', 0.5220940709114075),\n",
       " ('struggle', 0.5182028412818909),\n",
       " ('conflicts', 0.49886053800582886),\n",
       " ('pistol', 0.4968554973602295),\n",
       " ('threat', 0.4939129948616028),\n",
       " ('warfare', 0.4918963611125946),\n",
       " ('hostilities', 0.4856746196746826),\n",
       " ('rifle', 0.4836275577545166)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"conflict\",\"weapon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aae967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clashes', 0.5167396068572998),\n",
       " ('conflicts', 0.5029823780059814),\n",
       " ('disagreements', 0.48314568400382996),\n",
       " ('disputes', 0.4498971998691559),\n",
       " ('tensions', 0.44021129608154297),\n",
       " ('dispute', 0.4338757395744324),\n",
       " ('hostilities', 0.4326581656932831),\n",
       " ('reconciliation', 0.429973840713501),\n",
       " ('negotiations', 0.4135918617248535),\n",
       " ('antagonism', 0.4083492159843445)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"conflict\"],negative=[\"weapon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc08424a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"brazil chile france peru argentina\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf98c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0780152"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man','engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc993476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049329914"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman','engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e59e47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11197498"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man','power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e8d9c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0045317276"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman','power')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62d8000",
   "metadata": {},
   "source": [
    "## Cargar un modelo Word2Vec pre-entrenado para el español\n",
    "\n",
    "ver: https://github.com/dccuchile/spanish-word-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "148a6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('./data/SBW-vectors-300-min5.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "372eb1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33151585\n",
      "0.32905576\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('hombre','poder'))\n",
    "print(model.similarity('mujer','poder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17519ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29862916\n",
      "0.21502514\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('hombre','martillo'))\n",
    "print(model.similarity('mujer','martillo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1212fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
